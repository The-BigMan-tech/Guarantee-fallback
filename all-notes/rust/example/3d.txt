*Rigs bring life to a 3d model through animation
*when modelling first,should i create a proxy model first and then incrementally add details over it
*and if the model has bends,is it best to model it without bends like straight then bend it later.Im talking about block based modelling

*There are always properties:model properties,texture properties and animation properties.It is essentialy data that is used to fully describe an object in space.

*Bones,nodes and joints.A bone is a collection of nodes/elements and a joint is where a bone is rigged
*A bone is a folder,the nodes are cubes and the joints are pivots
*smooth gradient

*local scaling and global scaling

*pivot,keyframes curve

*so there is animation blending supported by the game engine like godot which is similar to tweening except that tweening is to create transitions between keyframes and is provided by the modelling software while the former is between animations

*Animations can reveal texture leaks

*BBmodel files are just json files with a specific format.
*gltf can be in json or binary files and are used for web dev
*obj is in a plain text format.It is a simple format and doesnt support animations and complex materials
*Fbx is in binary or plain text format.The plain text format is readable while the binary format is more compact and efficient.It is best for exporting/importing 3d models between modelling softwares and game engines

*the bin version is glb while the text format is gltf

*The animation editor is a board of keyframes
*The texture editor is a grid of pixels
*The model editor is for editing models

*sound  effect ad sound editor software.

*key frame animation--timeline board
*frame by frame animation

*block based modelling vs mesh based modelling.Block based uses many cubes and relies on placement while mesh based use one mesh and rely on tranformation of individual components like edges,faces and vertices/points.Block based models are in a tree which creates a rig where one part controls another.It involves direct transformation of these bones or folders while mesh based model separates the rigging from the model where you create a bone and the mesh deforms to follow the animation of the bone.in block based model,the rig is not separate from the model ie the groups themselve sin the tree structure is the bone while in mesh based models,the bone is separate from the model and the model is skinned onto the bone to follow it.

*Porting code over vs rewriting it,Key term here is preserve

*optimization by compressing,by purging,by a faster algorithm

*Binary files are specific to the hardware and architecture they run on and as such,a bin file isnt cross compatible with other os.

*Binary code is different from byte code.
*assembler,compiler,interpreter,JIT compiler

*assembly files are written in .asm files.
*raw binary in .bin files
*intermediate code in .dll files
*executable binary code in .exe files

*node js uses a jit compiler like C# and java

*Distributing an exe vs a builder for self compilation

*config files like properties are in .cfg or .properties cuz they are just mappings that hold k-v pairs while json documents are for serializing complex data

*curseforge is a repo for mods

*Full reloading and hot reloading

*A java file is written in .java but the executable is .jar and its compiled at runtie by the jvm

*i can change animation speed and model scale

*Baking isnt embedding

*gltf holds external resources like textures and animations by path references while glb embeds all of them in a single file

*Io bound task is a taks that waits for input/output operations to complete and not computations while cpu bound tasks are tasks that are bound by computation.

^The cpu is where the instructions are ran

*The os is an abstraction over hardware services.It is a safe way to communicate with the hardware

*Go runtime--M:N mapping,suspends,handles context switching.The runtime decides which goroutine runs on which OS thread(mapping) at any given time(context switching---saving state)
*so context switching in go is to suspend or allow a goroutine to run

*if a goroutine is deemed as suspended,does the go runtime refuse to map it to an os thread.The runtime continually checks the state of suspended goroutines. When a suspended goroutine becomes ready to run (e.g., it has the resources it needs), the runtime will then map it to an available OS thread for execution.The OS thread on which the goroutine was running may now be free to execute other goroutines. Is it that the go runtime will make the goroutine invisible to the os thread
*The Go runtime can now schedule other goroutines to run on that OS thread. This means that even though the OS thread is still active, it can be utilized for other work while the original goroutine is waiting.
*Once the condition that caused the goroutine to suspend is resolved (e.g., an I/O operation completes), the Go runtime can make the goroutine runnable again. At this point, it will be eligible to be scheduled on any available OS thread, not necessarily the same one it was using before.

*goroutines are lightweight and user level while threads are kernel level

^The os manages threading.Go runtime handles goroutine execution.

*concurrency means making progress in multiple tasks at once and not necessarily parallelism where tasks are executed at the same time

*coroutines are synchronous but it achieves cooperative concurrency by giving the developers explicit control of when the code will yield and resume execution of a piece of code.Is this a fourth type of concurrency and its similar to async where concurrency is still achieved in one thread

*async is just an implicit version of coroutines although,you can still have explicit control using the await keyword

*Time allocation
synchronous
Coroutines--explicit yielding and resuming
Asynchronous--implicit yielding and resuming
Multi-threading--time slicing managed by the os
Async-threading--goroutines and tokio blocks
Multi-processing--many cpu cores
Gpu processing--thousands of gpu cores

*A technique to organically displace parts in an animation:by displacing one over the other in opposite direction at the same time that other one is displacing
*android is a linux distro
*the creator of linux made git to manage the dev of the linux kernel

*Linux is a kernel.A distro is an os that uses that kernel as its core.The kernel was written in C

*GNU itself is not a complete operating system; rather, it is a collection of free software components intended to be part of an operating system. The GNU Project provides essential utilities, libraries, and tools necessary for a functional system, but it lacked a fully functional kernel for many years until it adopted the linux kernel to create a full os

*Many Linux distros use gnu utilities together with the linux kernel

*The kernel itself is isolated from the user and it interacts with the hardware through drivers and users can only interact with it through system calls to utilities provided by an os.

*An os is a combination of a kernel to communicate with the hardware and system utilities required to communicate with the kernel either through a cli or a gui while a distro is a complete operating system package that includes the kernel, system utilities, libraries, applications, and additional software tailored for specific use cases or user preferences.

*They all communicate through system calls but the way you communicate with them in the user space is into two:gui or cli.

*Code editor and an ide

*so a text interface is just a subset of a gui particularly for text

*interfaces are at the user level and they are used to indirectly make system calls to the os by the user

*System calls from--Cli,Gui,text interface,
*in the end,these commands are turned to binary data that makes system calls

*The shell,the gui framework and a programming language

*The programming interface,command line interface and graphical user interface.An interface is an indirect way to communicate with the os.The cli and programming interface use text but cli is command oriented while a programming interface is syntax oriented and a gui is visually oriented.

?is a programming interface the strongest way to communicate with the os since the available insteractions/tasks you can do arent predefined even though the individual lines are instructions that are predefined,its done in a way that when combine with others creates a new task that was designed by the programming language.It allows for creative commands

*Coding is made for problem solving while cpu commands are for direct commands to the cpu

*Commands are better for direct system interactions while code is better for solving user world problems
*Commands are closer to natural language while coding involves forging instructions.Commands are one off and direct instructions that gets executed immediately while coding involves writing instructions that adhere to a specfic syntax and are crafted with logic that will not get immediately executed by the system.They allow for creative instrcutions.A repl mimics the cli nature but for programming languages.

*Commands are written in a terminal while code is written in a special text editor called a code editor.

*Commands,arguments and flags

*It is very dangerous to run commands that you dont know as it may have destructive behaviour and lead to irreversible and damaging effects.

*Linux is more about communicating with the os through its powerful cli system

*Code is more about developing apps by using logic and algorithm design to solve problems while commands are about getting direct feedback from a straight instruction to the os without crafting logic.Linux is best for its commands to make many instructions to the hardware while windows and mac are better for developing apps and assembly in as much being a programming language is more of a command rather than code since that one too is focused on direct cpu commands.The Cli can be seen as an abstraction layer over assembly language. While assembly allows direct interaction with the CPU, commands in the CLI can represent complex operations that would be tedious to implement in assembly

*Most white hackers use linux commands for everyday tasks,tools for security testing and only write code when automating tasks,writing exploits,analyzing data for assessments or extending existing tools in what they provide.

*so white hackers have a discovery mindset to writing code which is an iterative process that uses previous outputs as data to write new code and detect any vulnerability while application developers write code with a building mindset to solve problems.White hackers rely more on data while app developers rely more on logic and reasoning to solve their problems and deliver functionality

*and thats why they mostly use commands because commands provide instant feedback which is data while app developers use coding which helps to craft instruction

*Commands provide an immediate feedback cycle while coding involves a slower feedback cycle as it requires testing and debugging.This is because commands are data driven where any data you get is all you need to move to the next command while code requires a functionality to be reached before moving to the next step

*The os provides communication with the kernel through a system call interface which is interacted through user level interfaces like the cli,gui or programming interface

*Commands are broken down into three parts:the main instruction,arguments and flags

*parasite polyglot

*C style/curly braces vs indentation/colon style

*Image data is stored in binary but turned to an array of integers for processing

*Environment package installer vs project package installer

*the standard output can be truncated.its the terminal/console and not the file system.This process of taking output somewher is called transport.

*I used ristretto for rust as it a warm color
*Octagon for typescript as it is a modern feel
*Spectrum for c++ as its contrats highlights its complex code
*Machine for python as its greenish tint gives a focus and comfortable feeling

*kali linux is a linux distro that packages many security tools together along with default configurations,dependency management and modifications/optimizations to these tools to make them easily accessible to the developer experience.Since kali has a lot of community support,it has been battle tested to be the best kit for security.

*These tools are made on linux because since linux is open sourced and customizable,one can tailor the os to work with these tools with the env they want and since its open source,there is more collaboration and many tools leverage linux cli to make many tasks easier and mostly because its widely used in servers

*In essence, white hat hackers primarily use established security tools to perform their work, utilizing the CLI for efficiency and automation. They may only code when necessary, either to customize existing tools or develop new solutions to address specific challenges in cybersecurity.

*securityware can be misused for malicious purposes.The reason why it is free and open to the public despite prior knowledge that it can be misused is because it provides a resource for others to learn about security,its open source nature/philosophy allows for easy collaboration,to raise awareness about vulnerabilities.They also do it for research.In general,putting limitations to these software for the public can make hinder more legitimate users than maicious ones

*Control vs Distribution

^Security research,security tools

^Zaid Sabih courses on udemy--for learning how to build security software

*White hackers hack to better secure their software while black hackers hack to have illegal priviledges to a software.

*Whiete hat:Find a vulnerability,inform,defend against it.
*Black hat:Find a vulnerability,exploit it,go to jail.

*Many black hat hackers that hack by misusing security tools are the less experienced and its mostly the ethical hacker and the security software programmer that actually have the knowledge and the experience.This is because the script kiddies often focus on using available tools without a deep understanding of how they work. If a tool functions effectively for their purposes, they may not see the need to learn about the underlying technology.This leads to them only having surface knowledge as they primarily focus on attacks while ethical hackers invest time in learning how various security tools work, the vulnerabilities they exploit, and the defensive measures that can be implemented.Their goal is to identify and mitigate vulnerabilities within systems.

*The professionals who use security tools to mitigate vulnerabilities--ethical/white hacker
*Those who create the security software that ethical hackers use---security software developer
*Those who misuse security software for attacks---black hat hackers
*Those who write viruses and develop malware---large criminal organizations.They operate like businesses


*Logic circuit design is a physical implementation of binary which is very bare bones
