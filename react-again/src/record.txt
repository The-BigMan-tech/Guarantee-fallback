a thunk is a function that returns another function instead of a state.Its used for performing side effects

ill use a progressive optimization technique where the core functionality is written in js at first using thunks and the code in the thunks is gradually replaced with rust calls

decoupling the implementation from the application

*local file manager
*cloud file manager

redux thunks for client side processing with side effects
rtk query for communicating with server side processing

redux state
reducers manages the state of the app
thunks orchestrates state and call side effect functions
side effect functions/utilities are separate and decoupled from the thunks

components dispatch thunks

undefined: Typically indicates that a variable has not been initialized. This can lead to ambiguous situations where itâ€™s unclear whether the absence of a value is intentional or accidental.
using null union ensures that a value can never be accidentally undefined

switch on union for safety similar to match enum case in rust

variables with no values leads to ambiguity about whether its intentional or by accident.so using null where possible is better so that you can clear this ambiguity and save productivity time from false bug hunting


async thunks and create async thunks

thunks dont return values.just dispatch actions

^react,tauri,pouch db,tailwind,daisy ui,redux,chart js,react-toastify,uuid,throttle-debounce,fuse js

hello pangea dnd,react router,framer motion,gsap,three js,
next js,auth js,paystack,prisma,postgres sql,mongoose,mongo db
formik,zod
web3forms
jotai
backend as a service or a nest js server

^uno edit funk download
^Conquest edit,invincible season 3 edit

relative ui sizes only makes layout responsive and not content 

client side apps--tauri with react,vue,svelte,rust for performance critical parts
server side apps--tauri wrapper,next js,nuxt js,sveltekit
client side with server side functionality---client side app with rtk query,Backend as a service/nest js server
server side app with client side functionality----server side app but with (redux,client components,pouch db)

implementation,interface,controller
database,file system,app state


TODO:download some assets
TODO:finish the layout of the ui

Todo:Art styles
3d illustration art
neumorphism and skeuomorphism art
minimal ui art
vibrant
animated
infographics
svg art
lottie animation

todo:resizable panels

3d illustration ai generator

fixed units---requires manual responsiveness,is faster:%,vh/vw,rem
relative units--constant calculations makes it automatic,slows perfromance:px

relative unit for layout
fixed units for content

safe assignment


*so components gets rerendered across updates and only app state is saved across rerenders.return values from function calls arent saved but rather recalled on rerender and since uniqueid isnt a pure function because of the unpredictability of output,the previous ids get lost on rerenders and thus the need to cache their iutputs using useMemo is required

*i could have made the conditional class logic inline by using the ternary operator but doing so will become catastrophic as the component grows because i will have to check each element that manages their own classes that they apply.moving it to a function that an element calls even if its one element makes it easier to reason about.the jsx shouldnt make any decisions on the app state or which classes to apply.they should just render ui.the only decision it makes is on what ui to render based on a condition it doesnt even check but one returned by a function.

*sub functions are the functions within the component function that handles component state management logic.They often read from or modify component state without directly embedding that logic in the JSX.sub functions only make decisions based on the component state but when it comes to the app state or global state,they only dispatch thunks that handle that logic and they dont decide which thunks to dispatch conditionally because they will be influencing the global state.The subfunction determines which ui to render and the jsx follows.

*jsx are no decision makers .the decision making is by sub functions even what to render is by a subfunction so a jsx rendering something conditionally is as directed by a subfunction.the subfunction will return its decision as either true or false and the jsx obeys.

*operations are better centralized than decentralized,have only one responsibility
*components are functions that return jsx.

*reusable styles will require a css file and not necessarily a style component or a string variable
*reusabel jsx can be done with components and props

*useMemo a hook for memoizing values in components.It helps optimize performance by recalculating values only when their dependencies change.Ideal for expensive calculations or derived data that you want to cache during component re-renders or for retaining the values of impure functions like a unique id generator

*React.memo is a higher-order component that memoizes the entire component. It prevents re-renders of the component if its props have not changed.Ideal for optimizing functional components that do not depend on internal state and only rely on props for rendering.stateless child components can be memoized

*regular function defintions for reusable logic and arrow functions for callbacks in hof
*another use case of arrow functions i found is that it looks cleaner for components that accepts props.they are also used for type annotating functions in interfaces

*most of the time,i dont use props because state can do everything i need but i think the ideal use case of props is for pure components.that is components that always return the same output from a given prop.unlike their parents,they dont have subfunctions to make any decision for themselves.they just take the sub functions of their parents and call them where appropriate non conditionally.They are mostly used to prevent rewriting jsx across a component.If they do make decisions,its only based on their own state.they dont make decisions about their parent state so they shouldnt directly have setters but rather subfunctions of the parents that do the decision when it comes to the parent state

*arrow functions,props and memoization for child components

*Child components--they are the same but they dont affect the state of their parents directly but rather use wrappers around setters provided by the parent and it should be changed non conditionally


^fs,path and os,win api
the os module is used to request general os services
win api is specifically for window services

todo:safe mode--changes to the fs through the app doesnt directly affect the real fs.this is to ensure the app safely access the fs.It will require a diffing algorithm and diff files that are loaded in memory.any attempt to write a file,writes to a diff file

design merging
primary-complementary design


lasnguage service provider--intellisense
linter---real time analysis
lexer---breaks the code into tokens
parser---constructs the ast from tokens
semantic analyzer--checks if the ast is syntatically correct
ir code generator
ir optimizer
asm code genrator
assembler
binary

?does php compile to html

software architecture
design architecture
algorithm design

*---------------------------------------------------------------------------------
implementation,utiilities--a bunch of tauri plugins
safe interface
selectors,reducers
thunks
components--state getter and setter,sub functions and jsx
Child components

higher order components
toast component

custom hooks
higher order thunks
cache utility--normal caching and ahead of time caching
app.tsx for setting up the app on startup using useEffects.like opening a tab on startup,caching specific folders ahead of time and deciding how the ui responds to aot caching
throttlers
*------------------------------------------------------------------------------------------

app state is global,component state is local

stateful child,
stateless child

custom hooks for reusable component logic
stateless child components for optimization and reusable jsx

anything that should cuase it to render when memoizing,should be passed a prop and checked for changes

ui framework compatibility tools-mitosis,astro

tauri uses wry as the webview library

todo:how to embed external binaries like node js into tauri
calling rust from frontend
calling frontend from rust
bidirectional communication

delayed runtime error--error-prone code may not immediately cause runtime errors till they are called.This is because writing error-prone code doesnt cause anything till you use them at runtime.

^with wasm,you can interop any programming language with js.so i will use tauri or was to bridge rust with js

unsafe but protected like for a new unsafe block,a new process is spawned and if it crashes,the program skips it

todo:vfs feature that uses a diffing algorithm
todo:virtual folder

frontend dev--content but exhaustive
backend dev--content but repetitive
cyber security--new content generated every day because of emerging threats
game dev--you can create any thing you can imagine as long as you can code it
data science programmer--new content because data changes per business
scientific programmer
cloud developer

the reason we use state on react instead of local variables for storing data is because components i react are functions and functions are stateless so when they rerender,the variable information gets reset but using state from a state hook ensures that the value persists across rerenders

you can return jsx with or without () because () is for grouping data but since jsx only has a single parent,there is no difference in using it or not but using () allows you to indent it below the return.

for a toast component that notifies the app on an error,define th error in the component and bind it to a use effect that calls the toast function to show the error but you should define the toast function in the use effect hook or it will always cause a rerender.you can define it outside of the hook but it will be more complex as you have to use useCallback to prevent unnecessary rerenders

everything used in a use effect hook thats outside of its definition must be a dependency so that it accurately reflects the current data.if a variable isnt tied to rendering of the hook logically,its better to define it within th euse effec hook to prevent it from being a dependency

*ui configuration to component with set attributes

toast emmitter is a local change while toast container is a global change to all toasts

*The toast component works by listening to a variable on the app state that keeps errors,infos or messages and when it changes,it uses a useEffect hook to respond to it.The problem is that the same error message wont popup again after it does once even if the error occurs twice.this is because the same error message means the state of the error didnt change for the useEffect to listen to but by using an id property that has its value generated by a unique id function at runtime,the same errors will popup twice even though the messages are the same because their ids are different.This is for incase someone spams something that gets an error and they need to know it gets an error each time and when they want to redo the same command for refreshing the component

?errors can be handled,transported or both

objects are for centralizing related data into a single variable

because the ids are supposed to be unique even for the same message,it has to be recomputed unlike elements in react list components that requires caching for the components to be properly tracked

*CODE SAFETY
type safety,memory safety,runtime safety,thread safety,access safety like mut refs
logic safety,external safety

difference between it will not x and it can never x
notes in my jotter
difference between safety and security
builder mindset vs the engineer mindset

even though thunks look like regular functions,they can only be called by dispatchong them even by other thunks


*error transports---log files,console,toasts
*safe interface,centralized error management,transport layer
*capturing the error,handling the error,shipping the error

*compile time errors,runtime errors,logic errors

setup--scaffold your project,a clear architecture,make small of the backend to think of your app in terms of functionality,make small of the ui to think of the app in terms of user interactivity.use that mindset to finish setting up the framework of the backend.so that when you go back to the ui,you can easily add features to the backend and connect your ui to it.the backend may not be finished at this stage just enough for you to have a structure of what you are building

^vscode tabgroups

*the thunks can also perform file system operations on the app level by leveraging other thunks

updating a state thats also a dependency in a use effect will cause an infinite call to that useEffect.You will want to break down that useEffect in two separate ones to prevent this issue while still retaining the desired intention:One for setting the state and another for reading it.In general,useEffect blocks shouldnt be large so that elements that dont logically depend on its dependencies wont render unnecsessarily.its best to use many use effect blocks that are just small enough to hold dependents than a big one.

*im storing cache data as part of the app state in memory and its only managed by thunks not components.components dont know the cache exxists

bitiwse,unioon and logical or

push,pop
unshift,shift
indexing for replacing
splice for inserting,deleting or replacing at any index

freeze the ui on loading

the asynchronous nature of the openInApp thunk is the reason why i dont see the results of the dir operation as soon as i opened it in the app but until i open another one even when i read the data only after performing an operation on it.

*The caching technique I used is not with local storage or pouch db but an in memory approach.this means that the cache is not stored on the disk and as such,it clears once the app closes.The cache is a property on the app state that's an array of objects holding two properties;the path to the folder that's being cached and the data which in this case,is an fs node.The cache grows on app usage where data is pushed as the app is used making repetitive patterns load much faster.This prevents space from being used on the disk and its  easy to implement.The cache though will need to be limited where it removes the first element as it exceeds it's threshold so that it conserve memory usage  but since the fs node type I made doesn't store the files content,only data like ext,path,icon and other metadata,I can make dozens of them without affecting memory.The content is loaded on demand from a function at runtime given that the path is provided.So regardless of the file size,all fs node types take almost the same memory.The length of the path is the only difference in memory which is subtle.So my cache can go to 40-50 of these and this is O1 space complexity too at that because the cache has a fixed size.My previous projects,I made both the thinks and components handle caching which raised complexity but now,the thunk manages caching and components will use the app state comfortably without even knowing of they are working with cached data or not.The thunk does this by setting the app state they listen to to the cached version till it's done loading where it will st the app state they listen to the version that was just loaded.Thjs preserves the user experience.When you add data to the cache,it will also check if it exists and if so,it will update it.The thunk will only cache after the it updated the ui allowing caching to happen in the background

I can cache 50 of fs nodes in memory cuz its just metadata really

cache limiting by number
cache limiting by memory

so even though the cached folders is fixed,the fsnodes in each folder can vary but thats not a problem since the fsnodes only contain metadata so having many of them isnt a significant memory hog.

metadata caching
full data caching

clearing the ui and transporting the error is better than crashing or exiting the process

freezing the ui

so freezing the ui when reflecting cached data and while relaying to the users that the new data is reloading. is safe because the cached data may not reflect the new data so users may interact with an unstable state and it prevents unintended actions from layout shifts upon reloading.so it means that the cached data is there for the ux and immediate feedback so that the folder wont look empty all the time they click on it but the time of interactivity is still the same.



*you cannot compare objects or arrays in js since they are done by ref not value

setTimeOut/interval,Promises,async/await are ways of async js

*states in react only change when rendered so if they need update based on state changes,they have to be updted in a useEffect but if they use a global app state,they stay subscribed and update when the app state changes.But if a state that depends on another state thats subscribed to the apps global state,it wont update when the subscribed state responds to global state changes.it has to be listened to on a useEffect which manually updates the local state thats connected to the subscribed global state
 
*my app only loads the immediate children of a dir and only loads the individual content when requested

I will have done ahead of time caching where all child folders of an opened folder are cached but since i only load one generation of child folders at a time,i cant cache the child folders because the next generation of child folders under those ones havent been generated yet meaning i have to do that before caching the first generation child folders.This is possible but not feasible and will cost runtime even though it happens in the background as some child folders wont be included in the cache when the cache reaches its threshold making it to use extra runtime for nothing and the cache limit also means it will be unpredicatable to know which child folder remains in the cache.the purpose of ahead of time caching was to improve ux by caching other folders when a foder is opened so that users dont see loading for them but it isnt feasible.

so if i want to do ahead of time caching,it has to be selective and only on app startup.selective ahead-of-time caching should definitely be optimized over time based on user behavior and performance metrics


the way my caching mechanism is means that there is no different between it and a skeleton in the sense that it isnt interactive except that it shows more information than it.the cache ahead of time worked except that there has to be a decent amount of time before everyhting can be cached so the user seeing a cached downloads for example when clicking it for the first time depends on whether he was else where long enough.but i guess ill leave it like that.its better than not caching anything ahead of time.i can decide to prevent interactions till everything is cached ahead of time but it spoils the ux as users want to work with something as sooon as they see it loaded an they wont like long loading times

the name cacheAheadoftime is by its context or use case not that it caches ahead of time.its a normal caching function but how its used qualifies it for that name.

debouncing prevents unnecessary caching attempts.debouncing made the ahead of time caching faster than when it didnt have it because caching the home tabs can be skipped by the app when the users rapidly switch between tabs on app startup.Also,the thunk only caches one tab ahead of time so its in the app.tsx file that ill decide the order in which they will be dispathed.By making the thunk to only cache one at a time,i can configure the order later and prevent all of them to be in one big promise waiting to be resolved at the same time but instead in smaller promises.


the pattern where the tabs are cached ahead of time sequentially automatically prevents the need for a throttle because opendir runs only after all the cachedaheadoftime functions because open dir awaits twice midway while the others only await once meaning that the app wont show the home tab till all the other tabs are cached ahead of time even though i placed openhome first.opendirinapp already caches the tab for me if it isnt being cached by the aheadoftime function so everything sorts out.So when i open the app,it starts at the home page and loads but while its loading that,the other tabs will be cached unlike where i did everything all at once under thunk where even after the home page loads,some may still be under caching.The only thing now is to ensure that the app remains uninteractive till the home page loads.

its better to break async tasks that repeat tasks into independent async tasks so that they can be managed effectively

so not only is the caching ahead of time but just in time meaning that once the home page loads,everything that was cached ahead of time is guaranteed to be cached.the feature where the other tabs are cached as soon as the home tab loads created itself out of the fact that the caching operations are async and separate

The opendir function skips over caching tabs that have already been cached ahead of time.this is to prevent switching between tabs to cause unnecessary attempts to cache when the tabs are still being cached ahead of time.but it will be a problem as the cache wont update on subsequent folder updates so i made each aheadofcache function set a state that indicates to the app when it has finished.This is my way of invalidating the cache of the ahead of time caching

he cache is limited by instances of 20 and the individual fsNodes array of each instance is limited to a 100

i just realized that prints in async blocks may not show in the order they were executed.so they are a bit unreliable i believe.

there are two types of caching.just in time caching or ahead of time caching.jit caching costs runtime but no startup time while aot caching is vice versa.jit caching should be used to cache evrything because it ensures that only accessed data is cached but aot caching can be used to improve ux but it must be selective so that it doesnt take too much startup time or waste cpu and memory resources and must be async.

jit caching is defined and initiated at the thunk level.

the aot caching state is read by the app and used by the app to control the freezing of the ui and as such,it isnt manged by a thunk.the aot caching is defined at the thunk level but its initiated by the app and the app component that decides how the ui should respond to it


*there is css,
*sass 
*tailwind css as in with @apply directive.its css syntax but for tailwind
*tailwind themes as aliases
*styled component
*tailwind styled components

*prolog is for old school ai

if you dont invalidate a memoized component,it will see an older version of a state and not behave as expected

*just in time/on demand/lazy
*ahead of time/eager

mine freezes the entire ui till everything is cached ahead of time.i can do a progressive aot caching where users can access data that has been aot cached

jit caching is best for unpredictable access patterns and frequently changing data
aot caching is best for predictable patterns and very stable data

AOT is best for
Data that is accessed very frequently.
Data that is critical for initial application functionality.
Data that is relatively static.

*so the reason why my component doesnt reliably call the cleanup function when it exits is not because of js or react but because its impossible to guarantee that the app will have a clean exit as many circumstances can prevent the app from closing in a stable state.task manager is an example of this,it forcefully exits a process but closing the window normally,gives the app the chance to cleanup and thats why force quit is faster than normal quitting.React's useEffect cleanup functions are designed to handle the component unmounting or when dependencies change. They are not intended to be a guaranteed "on-application-exit" mechanism

this wasnt immediately obvious because theoretically,it will provide a reliable exit and js cant warn the programmer about all possible operations that will unreliably run when placed in a use effect.so useeffect is for managing app resources that arent critical to the functionality of the app.if i need to persist data when the app exits,i have to create the solution myself.

so external code safety can never be guaranteed because its the fundamental limit of computation as described by the halting problem.

retry mechanism is a way to solve transient errors which are errors that only fail on a lack of certain conditions.fallback,rollback,fault tolerance,indempotency means that performing the same operation many times is the same as performing it once.its like the safety of a pure function but in a function that does side effects

*if i want to reliably persist data,i can use a polling mechanism,retry mechanism or checkpointing for persisting data.

*so making a requirement like only once for a design architecture where the app only stores the data when the app is not in use is a bold requirement that makes it complex to guarantee.

*so at-least once persistence is better than only-once persistence.so the limits of computation affects design decisions because under ideal conditions,one can design his app to only persist the data once the app is closed.In the real world, systems are subject to failures. "At-least-once" acknowledges this reality and prioritizes ensuring the data eventually gets persisted, even if it means potential duplicates.This is why persistent operations must be indemptotent and a retry mechanism must be implemented

perfect reliability and predictability isnt possible in computation

only-once is the ideal condition and at-least once is the real condition

theoretical designs mostly consider ideal conditions then it will convert to a practical design because it now starts to consider real world conditions

app level startup operations more reliable to execute than on exit operations since the app only starts under some normal conditions that can reliably execute the startup function.The phrase "normal conditions" is crucial here. Startup operations are designed to execute under normal conditions. The application expects certain resources to be available, certain dependencies to be present, and certain configuration settings to be valid. If these conditions are not met, the startup operations may fail.


todo:checking on exact matches of strings is error prone without consistency.change all of those to distinct states.But it will do for now.Using string transformations like decapitalizing the string and trimming off white spaces can make the match less sensitive and thus,less error prone.



items in the recent folder are links

incremental processing

so i can get predictable incremental processing unlike removing the await blocks

Predictability: The order in which the promises are initiated is predictable. The order in which they resolve might not be, but you can handle that.

*so returning promises creates predictable async operations but removing await keyword on unresolved data will give unpredictable async operations.it may not behave as intended and is error prone.You're then trying to use data that might not be available yet, leading to errors and unpredictable behavior.

*im returning an array of fsnodes promises instead of processing it all at once before returning or rather than using a generator for them because its easier to write and understand than an async generator.

*incremental processing shows more progress than all in one processing but in my specific use case,its slower even though it incrementally shows progress because each time i update the ui when a promise resolves,the ui has to take its time to update rather than the previous one where it updates all in one go.so i will only use it for the home tab which is the first tab that loads when you open the manager.so that the users can see a visual indicator that the files are loading while the app is caching some tabs ahead of time.to prevent the number of ui updates,i will batch five then push.

*one can argue that doing ahead of time caching and incremental processing only cost additional runtime but im only doing incremental processing on the home tab to leave a better user experience.even if its slower than all at once,the user can track progress as the app opens instead of a blank slate that just gets filled all of a sudden.it builds reliability in the app and then,the other tabs can then be loaded all at once,it will look like the app just became suddenly faster after the initial load further building reliability in the app.the caching also also ensures that users see a cached page thats showing a load in progress since the app only loads one folder at a time so that they dont see a blank page that saying loading.so ahead of time caching for the six tabs on the sidebar ensures that the user always sees progress.so this specific scenario is an example of when user experience is more important than runtime.the rest of the app can do all at once loading.

*You're tailoring your loading strategy to the specific context of each tab. The home tab prioritizes initial impression, while subsequent tabs prioritize efficiency.

*so in general,comparing arrays by using a deep comparison is highly inefficient especially if the condition check is only used frequently as the time complexity is O(n) but the direct approach uses logical chainshas with a time complexity of O(1) making it extremely fast and independent of the size of the array.so comparing arrays based on logical chains is more efficient cpu wise than deep comparison but the deep comparison can be potentially easier to read than the logical chain and can apply to a wide variety of arrays than logical chains that are tightly coupled to a particular condition

*so wrapping a function asynchronously through a promise or async marker doesnt make the operation itself async only the result of the operation is treated as async and any other operations in that function that work with async results

*so async and promise only defer the result not the operations leading to the result but the only operation that gets deferred is one that depends on a deferred result.The operation still runs when and where it would have without the async/await or Promise, but the code that depends on the result of that operation is deferred.

*IO operations like network requests,disk and databse operations are blocking and expensive to perform.There are three ways of doing them;onEveryChange,at-least once,at-most once and only-once.only-once is feasible on startup but unreliably on exit.it is done assuming ideal conditions but in reality,at-least once and onChange are the only ones that are computationally feasible but onChange is highly inefficient because it will block the main thread.if i make an app that launches a network request on every button click or the app wont work,the app will have an extremely poor performance because its heavily reliant on io operations and performing them onChange is runtime expensive and the app cant afford to make it async because it will lag on interactions.An app should use io operations but not heavily reliant on them.The at-least once approach is the most practical approach to handling io operations.It ensures that an app does an io operation at least once because its dangerous to make it run only once as external factors can break this guarantee especially on exit operations.It can be done in many ways such as a retry mechanism,based on frequency or asynchronously.

?service workers and web workers

*so a side effect is when a function modifies a parameter in place/mutation or performs an io operation.Pure functions are more predictable because they dont have any side effect.if a function must perform a parameter side effect,the programmer must ensure that its clear and concise to preserve predictability but if the function performs an io side effect,it must be indempotent.its an io side effect function that intends to act like a pure function by ensuring the overall state change caused by the function is the same, regardless of how many times it's called with the same input.

*so an indempotent result is that:if i attempt to perform x multiple times with the same input,it only performs x once and does nothing on subsequent calls

^i want app.tsx to be responsible for persisting the inmemory cache and loading it again to memory and caching objects ahead of time.


*Local storage has a limited storage capacity (typically around 5-10 MB per origin). If your cache grows too large, you could exceed this limit, leading to data loss or errors.Writing to local storage too frequently can impact performance, especially on low-end devices.Reading a large cache from local storage on app load can also cause a delay.

*using a blind timer like setinterval is unsafe.it can perform unnecessary writes even if the data hasnt changed which wastes cpu resources.If the timer takes longer than programmed which can be influenced by external conditions like a slow device,the next setInterval execution will start before the previous one finishes. This can lead to race conditions, data corruption, or performance degradation.


*The setInterval timer itself has a very minimal performance impact. The overhead of setting up and maintaining the timer is negligible. The real performance bottleneck is the localStorage.setItem() operation, which is synchronous and can block the main thread.


A time window,time interval,timer


*throttling and deboucning are both techniques used to limit the frequency of function calls based on a time window to improve performance except that throttling only calls the first or last function call to arrive within a time window while debouncing only calls a function after the function hasnt been called for a time period/a period of inactivity

*leading throttling is that only the first call to arrive in the time window is executed while trailing is that the last call to arrive within the time period is called.The time window reset again to 0 to allow for new calls to arrive.

*Throttling and debouncing can indirectly increase the likelihood of no race conditions.However, this is a side effect, not the primary goal. Debouncing doesn't provide any guarantees about the order in which requests are processed or responses are received. It just reduces the number of requests.Debouncing is a rate-limiting technique, not a synchronization mechanism.Throttling and debouncing dont know anything about the app data so they arent indempotent

*The difference between at-most once and only-once is that at-most once only calls a function once within a time window ensuring that other calls during that time are ignored while only-once calls the function once within the app's life cycle.

*the main issue of putting a throttle in a useEffect that listens to data that changes on every button click for example is often that the throttled function is being recreated on every state change. This defeats the purpose of throttling.

at-least once uses an interval
at-most once uses throttle or debouncing.at most once prevents unnecessary writes.

^async database

*reactive io + throttling = at-most once.so store data to local storage is throttled meaning that on every call to it which happens on every add to cache,only one will be executed during that time window.It will be more effective if i increase the time window so that if a user clicks a button like five times,it only calls the store function once and since the cache needs to be up to date,it has to be trailing throttling.A shorter time window will result in more frequent updates to localStorage, while a longer time window will reduce the frequency but potentially lead to slightly older data being stored

*so if i used an interval like set interval,it will be an at-least once approach like store the cache to storage every 10 seconds but its more fragile because it makes an assumption that the cache may be updated within that time which cant be guaranteed because of different user behaviour and it will waste resources as there may be unnecessary writes

*The types of io operation techniques are only-once,at-least once,at-most once,reactive io,manual io
*so only-once is the ideal io operation techique where the io operation is performed only when the app starts or exits.startups are feasible but work under assumptions while exit io operations can only work under absolute ideal conditions.At-least once,at-most once and on-every-change are the only practical approaches.at least once is better for retry io mechanisms like constantly trying a request till it succeeds but it requires that the functions are indempotent and its fragile for operations that depends on data changes,at-most once is best for io operations that depend on data changes.It combines reactive io with rate limiting mechanisms like throttling or rate counting.Reactive io deivers io operations on changes to the app state and its the easy way out but highly discouraged to be heavily relied on because it significantly spoils performance.Manual io doesnt face the challenges of others because it shifts the responsibility to the user but it risks data loss if the app doesnt close gracefully,it creates an inconvenience for the user and it isnt best for background operations.on-data-change is feasible if the operation isnt meant to be frequently done and its lightweight.many applications still require manual io for a lot of functionality like deleting a file when a user does it.

^Extra notes on io
*the implementation of the trigger is what truly reveals the reliance
*Io operations have this complexity because its outside the control of the codebase

^IO optimization
*batching,throttling,debouncing and async io are optimization techniques on io operations not delivery triggers or semantics.because without them,it means that every trigger to an io operation will block the main thread to perform the io operation

*Batching is not a way of delivering io like reactive,manual or at-most once.its just a way of handling how many io operations are done at a time.Its an optimization technique

*Throttling is not necessary to achive at most once.its naturally at most once but throttling is an optimization mechanism

*Debouncing:you know it already

*Asynchronous io operations

^IO delivery trigger:What triggers the io operation
*manual io:Done in response to user events
*reactive io:Done in response to changes in the app's state.
*automatic io:Done automatically in the background like a retry mechanism


^IO delivery semantics/guarantees:What are the guarantees that it will perform the io operation
*Exactly-once:The ideal approach where the io operation is done exactly once.It guarantees that the io operation will be done and only done once.It combines the guarantees of at-most and at-least once approach or the other way around that at-least once and at-most once approach are techniques that  only implement one guarantee because onl-once relies on assumptions and ideal conditions that rent just computationally feasible
*Here,x = 1

*At-most once io means that the operation is either done once or it isnt done at all.There is no guarantee that it will be done.But it guarantees the same operation wont be performed twice to prevent unnecessary io operations.It isnt reliable and cant be accepted if data loss is unacceptable.At-most-once is the default behavior when you don't have any retry or acknowledgement mechanisms like atomicity
*Here,x = 0 or x = 1

*at-least once:The io operation will be attempted multiple times till it succeeds.It ensures that an io operation will be done but doesnt guarantee the number of times it will be done which can lead to duplication if the operations arent indempotent and even if they are indempotent,it can waste runtime unnecessarily
*Here, x >= 1

*Effectively-once:approach is a practical attempt to do exactly-once and acknowleding real world cases where it may fail.its a real world approximation.Because of its complexity,its not used for applications but sophisticated systems like databases.
*Here,x ~= 1



^How io trigger choice affects application dependency on the io
*Reactive I/O (Highest Potential Dependency):This implies the highest dependency because the application's core state transitions are directly tied to the success of I/O. If the I/O fails, the application's behavior is immediately affected.
*Its for io operations that are valuable and critical.should be used judiciously.It has a high trigger frequency

*Manual I/O (Moderate Dependency): This implies a moderate dependency. The application functions independently of I/O until the user explicitly requests persistence. Data loss is somewhat acceptable otherwise the responsibility wont be shifted to the user, but it's still important enough to provide a mechanism for saving.
*Its best for io operations that are valuable but not critical.It has a moderate trigger frequency

*Automatic I/O (Variable Dependency):The implementaion decides how much the app relies on it
*Whether its valuable,critical or not depends on the implementation.It also has a variable trigger frequency.You can use intervals or debouncing to do this.so even though reactive and manual io patterns can solve cases of critical and non-critical io operations,automatic io is done where conveniency is needed or if the io doesnt have any specific trigger rules that it just fits perfectly in the background.

*so the trigger pattern is about how reliant your app is on the io operation while delivery is about the level of guarantee you expect that an io operation will perform and perform correctly.The trigger pattern defines when the io operation will be initiated.



consistently audit code that uses relatively old libraries.dont use absolutely old libraries

*i can only throttle a normal function and not a thunk.Because the throttle is only controlling the outer function, the inner function is dispatched every time throttleStoreCache() is called (within the throttling window).You need to throttle the execution of the thunk, not the creation of it

*so type assertion is to relax the ts compiler in situations where we are sure of the type but its too complex for ts to know that. You use them when you have more information about the type of a value than the compiler can infer.This often happens in situations where:You're working with complex libraries or APIs where the type definitions are not perfect.You're doing some advanced type manipulation that the compiler can't follow.You're absolutely certain about the type of a value, even though the compiler is complaining but if you're wrong about the type, the compiler won't catch the error, and you might end up with runtime issues.

useMemo is for memoizing data while useCallback is for memoizing functions and React.memo is for memoizing components.They both take what the y memoize and a dependency that invalidates the memoization

*so throttle + useEffect just gives us back reactive io io but memoizing it gives us the at-most once io approach.

*so faulty type errors result when a script that doesnt officially support types is given by external declaration files which may be incorrect or out of date.This can cause false and misleading compile time errors that will take hours to figure out.declaration files provides the ts compiler with information about the types of the data used in the codebase and if the information is broken,ts will falsely flag code as type errors.The ts compiler blidly relies on the d.ts information over runtime functionality because its impossible for the compiler to analyze runtime behaviour.so the work around is to use runtime behaviour to analyze declaration files

im choosing to use spreading to the fsnodes array instead of pushing to it incrementally.it has a bigger time complexity of O(n) since O(n + 5) = O(n) as i only concatenate an array of 5 elements at a time but in exchange of faster runtime by reducing constant ui updates instead of pushing which has an O(1) time complexity but costs runtime as the ui has to respond on each update

increasing the time window of the throttle reduces the function call frequency but creates a lower chance of the function actually getting called if anything that will compromise the app should happen within that period

i made element eviction from a cache to start at the 8th index instead of the first its the same effect as shifting but it does this starting from index 8 so that the ones that are cached ahead of time will be preserved on the cache threshold.


so html already has previews i can use like text area,video and img.i can just use that.is there any other previewer i may need


video,audio,txt,pdf,<> file,word,zip,json,xml,exe,msi

^TODAY
recent folder-fixed the breadcrumbs,added support for it and cached it ahead of time
made incremental processing on the home tab
did at-most once cache serialization with throttling
preserved aot cached tabs when the cache reaches its threshold
smart reloading
file icons--ongoing
file search,debouncing
framer motion
todo:recursive file search
todo:search result caching
smart recursive file search--it only recursively reads the dir till it finds its search
todo:previews--video,img,audio,text area tags,react pdf,highlight js,react player,mammoth js,three js,react window
todo:file editing on the preview editor
todo:file actions on a pane --state modification,io operation for significant performance
todo:file actions on right click
todo:index for in dir file actions and a transfer object for move-like file actions
todo:Changing the view layout and icon size
todo:Change it from local storage to pouch db for async database
todo:File content search
todo:Details pane
todo:disk usage progress bars
todo:responsive
todo:diffing algorithm
todo:smart automation,heavy customizations
todo:vector database search

todo:Learn search theory

react window uses virtualization which means it lazily loads the content to the viewport.

memory theory
type theory
error theory
io theory
thread safety theory
immutability theory
indempotent theory
test theory
stale data theory
big o notation theory

*stale data theory concerns about the factors that causes the timing of read and write operations to the same data to be misalligned which causes working with inconsistent or outdated data

opens a dir to read its contents,gets the metadata and construct objects.doesnt read file content yet
file content is read on demand
since only one dir can be opended at a time,opened dirs are cached
cache instance limiting,fsnode limiting
updating the cache on loading
storing the cache using at most once and throttle approach 
selective ahead of time caching
incrmental loading
smart reloading--automatic io,background process.no need to worry about layout shifts in the sliced cached data.data will be added incrementally

grid vs table

version control--diffing algorithm
databases--effectively once,io approach

translucent tb--acryclic,clear


smart loading is composed of a rust file watcher,a bacground process that uses it and a debounce function


*im thinking of implementing smart loading in my file manager.my file manager can only read and store one dir at a time in the app state because of performance and memory but i use a cache to keep track of accessed dir data and display that whenever a user opens a dir while the app reads the dir again because of the possibility of data change in the fs between the caching and time of loading the dir.so what im thinking is that ill use a background process that can watch the file system of a dir and its only when that wathcer reports a change,that my app will reload the dir while displaying the cache data for the user to see progress,else the cached data becomes the loaded dir.no need to read it again.

*the purpose of the smart reloading is to prevent the app from reading unnecessarily from the filesystem when the cached data is up to date.without this,my app will have no way of validating if the cache is up to date with the fs and has no choice to go the safe route of rereading it while the cached data is being displayed to the user.Its going to watch only the immediate content of the dir since the cache data only has the path and data of the immediate directory not its children.the children are treated separately as their own instances in the cache to promote lazy loading.so ill have only six file watcher instances which means that its selective file watching.In case the file watcher didnt report changes for the app to reload the cache,i will have a function that runs every 10 seconds of inactivity to reload the dir of every cache.

the only reason why the cache can be invalid in my app that it requires reloading is because changes to the file system can happen outside my app.if it were only within my app which isnt possible,it wont need to have a smart loading feature.Because external changes are the issue, a file system watcher is the ideal solution. It passively monitors the file system for changes made by other processes and triggers a cache reload only when necessary.

^notify,home crate for rust

file modifications are internal changes so my app doesnt need to refresh the page.the changes will then persist to the fs

*Tauri has a bunch of plugins and i already made som myself but the best practice is to leave my custom functions the way they are as they are stable and use tauri plugins on subsequent use cases of low level functions

selective and non recursive watching the home tabs like i didi for selective ahead of time caching

*by default, Tauri restricts access to potentially dangerous commands like file watching for security reasons.

*This module prevents path traversal, not allowing parent directory accessors to be used (i.e. â€œ/usr/path/to/../fileâ€ or â€../path/to/fileâ€ paths are not allowed). Paths accessed with this API must be either relative to one of the base directories or created with the path API.This means my app just cant access any path

*tauri file watchers are saf and secure

*Use your own Rust binaries or custom Rust code for low-level or app-specific file system operations where you need full control or specialized behavior.
*Use Tauri plugins like the file watcher plugin for complex, cross-platform features that are already well implemented and maintained.
*This balances control, security, maintainability, and development speed, playing to the strengths of Tauriâ€™s architecture and ecosystem.

i had to change permissions and capabilities

*so using variable is type. is used for creating type guard functions

stale reads
race conditions

runtime safe doesnt mean its logic prone.

false type errors

*most logic errors arent complex but just overlooked small mistakes that are good at hiding themselves in large codebases making the developer think an error occured as a result of a higher level logic.This is because they dont crash at runtime and are type safe,so its often believed that it worked as expected so one can think its something he forgot to do somewhere.they can be based on assumptions,incorrect condition checks,etc.assumptions can still be made even with type safety because a type doesnt describe the particular context of the data.I think the best way to avoid assumptions is to log data that you arent sure of but the other logic errors need good attention to detail

*testing can prevent logic error

*a way to ensure predictable behaviour is just to return the modified array to the caller so that regardless of mutation,the caller gets a consistent array state.If you mutate an array inside a function but donâ€™t return it, the caller may not realize the array has changed, especially if the reference was reassigned internally.



smart loading cache validation is false on startup incase any changes happened to the fs when the app was closed as the app cant track it

the aot caching state is directly tied to the opacity od the app
the loading message is directly tied to the opacity of the files

added auto refreshing on top of smart loading

todo:dont make the opacity of the ui tied to string data

Breaking down a large task into smaller functions can give you a sense of progress and control. It feels less daunting to work on a series of small, manageable functions than to tackle a single, massive block of code.while the total number of lines of code might not decrease significantly, organizing code into smaller functions reduces cognitive load, improves readability, promotes reusability, and creates a psychological effect that makes the code feel smaller and more manageable.

lazy dir reading
lazy file reading
caching opened dirs
cache mamagement
selective ahead of time caching
cache persistence
Incremental ui loading
selective smart reloading
auto reloading
background auto reloading

time complexity optimizations
implementation optimization

multi threading read dir

*wrapping try catch in several areas of the codebase unnecessarily will only catch symptoms not errors.It wont help you find the root cause of a problem

include,startswith,endswith,equality,particular case conversion for case insensitive searches
glob patterns
regexp
search library--typo tolerant,name based search but not content based search
search engine--content based search
vector database--content based search

*Types of search
keyword search
fuzzy search
index search
semantic search

low threshold--strict check,less noise
higher threshold--loose checks,more noise


prolog
natural language processing
vector database in rust

if search result is none,display the fsnode array

ill use debouncing on the search

*The tooling ecosystem is beautiful

for an array,i use three states.null means its absent,[] means its present and [value] means it has values

*from now on goin forward,ill do direct toasting in my thunks but gradually since a number of them still use the component.My toast component has lots of issues

sidebar,body,topbar,fsnodes

*so animation costs performance and as such,it must be selective.They must only load at key moments and not continuously

^debouncing is better for actions that depend on inactivity like use input
^throttling is better for continuous actions like writing to a disk

*debouncing with leading execution is seamless which searching.its what ive been looking for.debouncing with trailing execution makes it feel a bit laggy but when it comes to writing data to a db,throttling with trailing is better than leading because it ensures that the writes are uo to date

*so both throttling and debouncing optimize call frequencies but debouncing main concern is the final or initial state of data without caring about the guarantee that it will execute  while throttling main concern is to regulate function calls but also has caring about the initial or final data as a secondary concern.initial debouncing prioritizes responsiveness while trailing debouncing prioritizes the final data by leveraging inactivity

strict and loose option

*so stale state reads in react since states updates async can be avoided by passing it as a parameter to the function that relies on it or putting that function in a use effect 

*so debouncing is meant to have a smaller time window while throttling can have a moderate sized time window depending on use case.Why?Debounceâ€™s goal is to reduce noisy rapid calls by waiting for a pause, so a smaller delay keeps the UI responsive without flooding calls.Throttleâ€™s goal is to limit call frequency over time, so the interval can be adjusted based on how often you want updates or saves to happen.

*so because the dir is large and there will be more files that may be relevant to the search,a threshold of 0.4 will be better and ill increase the debounce timer to 500-1000ms.

*Directory size and variability: As you noted, directories can be very large or very small, and itâ€™s hard to predict which directories will be searched again during the process lifecycle. Caching the entire recursive directory contents would consume significant memory and may quickly become stale or invalid.

*Caching entire recursive directory reads is often impractical due to size and unpredictability, but caching search results keyed by query and path is a practical, memory-efficient way to improve search performance and user experience.

todo:Recursively search till you get a good math score
todo:ill do it as quick search and deep search
^recursive search requires trailing debouncing unlike surface search that is better with leading debouncing

^never await a throttle or debouncer

*useref,usememo,usecallback

*i removed debouncing for the search.the search only proceeds if the user presses enter as they are no async solutions to debouncing