!We use environment variables in the .env file to store sensitive information that will be used in our code.The .env file must be ignored by git and not pushed to the public to prevent password leaks and since configuration variables changes per environment--locally or deployed,we use env variables to store them.

!Pray for Adelani
!Be secure with your current password.Make a new set of secure passwords for the tools i use.
!epic fight minecraft mod and addons
todo:Learn about package managers in detail:npm,pnpm and also npx
todo:Learn how version control works in detail
todo:SWC compiler,tsc compiler,Babel compiler,llvm.
todo:Understand the inner workings of electron,tauri and node js and the various browser components that makes them work
todo:Time series data and time scale db
todo:There is transcrypt compiler

todo:Automatic refresh in rtk query
todo:I should use pinno in redux middleware for logging app interactions
todo:Deno has native support for ts and prevents npm module vulnerabilities by allowing code to access what you allow and also,it is faster than node js.With deno,there is no need to setup typescript with the tsc or swc compiler but because type checking in deno costs a lot of time,ts files dont get type checked before
todo:Vite is primarily a web bundler but it is also a scaffolding utility for many kinds of web projects
todo:learn about AMD js modules
todo:Check on elastic search
todo:trpc is an e2e type safe implementation of rpc which is an architecture that allows clients to remotely call functions on a server instead of through http requests.Next js uses something very similar to this for its ssr
todo:testing,debugging,logging,documentation,type safety,request safety,database safety
todo:Cloud database services--Mongo db Atlas,Neon
todo:My deployment solutions--(Tauri or netlify) for the frontend,(docker and render) for the backend and since render and many other Paas services dont support docker compose,ill use the cloud version of my databases to deploy the database.
todo:After making a nest js backend that has everything i want setup,i'll create a scaffolding utility that will automatically scaffold a barebones of that for me
todo:Dont solve problems that are really not a problem
todo:Dont context switch between programming languages
todo:Curl
todo:Schema definition language--single source of truth for defining the schema of the data.
?wsl
?environment variables on the system allows us to access software from anywhere in our system using the command prompt or powershell

^switching vocals with nightcore music from skylest
^Better anime power:His power is statelessness meaning that he never retains his state as all state is lost over time giving him the power of respawning like in video games

^This is my table printer toolchain for postgres:I used the postgress js package to retrieve a postgres table into an array of objects.I then used the json2csv module to convert it to a csv string and then write it to a file using the fs module.I then used a vscode extension to turn that csv to a beautiful table of my postgres data.

^Becareful of keybindings as they may conflict with the keys as you type

?Python has a static type checker like eslint called mypy
?loose,strict and deep equality

*when elements in a data structure needs to be unique,you use a set
*The http verbs are purely semantic.Same thing as html semantic tags

*The types of root operations are queries,mutations and subscriptions but they are all the same other than their descriptive names.Its up to the implementation of these queries.

*A graphql object is an object that describes what data we can fetch and what field it has
*We select the root object,then the specific object we want to select
*Graphql is all about selecting fields on objects
*Graph ql objects and the functions that returns the data in each field of a graphql object

*There are three types of graph ql request operations;query mutations and subscriptions just like get,post,put ,etc
*Graphql has a SDL like prisma

*Because graphql supports many programming languages and backend frameworks,its documentation doesnt provide any specific code implementation on using it but rather,explains the concepts and how they work

*Because graphql allows the client to control the response he wants through the request,he doesnt need to know much about how the server works
^----------------------------------------------------------------------------------------------------------
*The two layers for data on the server are:the app layer and the database layer.At the app layer,we use dtos and schemas.The dtos through class validataor with class transformer and zod define the shape of the data that will be received by a request together with nest js pipes for validation and the schemas either through a SDL or a using a class with decorators are used to define the shape of the data at the database layer.

*Use interfaces for objects that only store data and use classes for objects that will need to have methods to perform complex operations on the data they store.

*Mongoose to mongo db and prisma to relational dbs like postgres
todo:what does skip lib check do
*In sql,we use a foreign key to create a relationship between two tables,but in mongo db,you can directly nest documenst

*The relationship must be represented in a converse statement
*For one to one,the relationship can be defined anywhere but the related field on the opposite entity must be optional.
*For one many,the relationship must be defined in the Many part of the relationship and the opposite related field doesnt have to be optional

*A relationship must exactly have two related fields that relates two models together meaning that the models to be related must use each other as types in one of their fields.Then in one relationship end,we use the relation attr modifier to link another scalar field which should be separate from the primary key and act as the foreign key and reference it to the primary key of the other model in the relationship.The foreign and primary key must have the same properties meaning that they should have the same datatype and be both unique.

*A relationship is a connection between two different models in a data model.They are in the orm level and dont persist to the database.A related field is a field that its type is a model.

*Sql uses the id to perform safe write operations like preventing inserting a record twice and without the id,you can delete multiple records by attempting to delete just one because of the possibiity that they are the are the same.The id also provides atomicity by providing a way to track changes to an element and rollback without affecting others

*Type modifiers are used to modify the types of the fields in the mode.They are [] for array and ? for optional.The ? maps to NOT NULL and by default,any field that doesnt have it will have this constraint.

*There are inline and block,Tag and functional 
*Attribute modifiers modify the behaviour of these fields in the database like @id @unique and @default().You can also use block attributes like @unique([]) to make multiple fields unique.In other words,there are inline attribute modifiers to target one field and block for targetting multiple.Some are just tags while others can be functions

*Attribute modifiers are used for defining additional information about how fields should be treated by the database that cant otherwise be represented by just types alone.They can define constraints,metadata and their behaviours with the database.They begin with @ like id,unique,default.

*There are two categories of attr modifiers:inline and block,flags or functions

*The model definition resembles that of an interface but without the commas
*a model is made up of a field name,type,type modifiers and attribute modifiers that can be used with the @ syntax.\

*functions are best written in camelcase and classes in PascalCase
*prisma models are mapped to lower case names
*You cant modify the schema or generate a client when there is an active server consuming that.
*A migration is a function that modifies the schema of the database
*prisma migrate makes migration easier as you dont need to specify the actions that lead to a change in the schema,you only need to describe the new schema

*An active record ORM by the name,is an orm where the model itself directly controls the table.This means that changes to the model directly controls the table and the model is aware of the database.It is simple and rapid to use but becomes more bloated and less flexible as the complexity grows.

*A data mapper orm decouples the model from the database.There is a separate layer that maps the model to sql queries and in prisma,it is done with the prisma migration tool meaning that the model is unaware of the database.This ensures that changes to the model doesnt directly alter the table.It brings some setup boilerplate but in exchange for greater flexibility,easier tests and adherence to SRP.

*Arrays,objects and table are big data structures.

*a pointer is a variable that its value is an address to another variable.It can be reassigned and incremeneted or decremented also called pointer arithmetic while a reference is just an alias for an object and in many pl implementations,arrays and objects are passed by reference.A reference cant be null so they are null safe and its also immutable

*a 2d array or matrix is not a table.A matrix is for numerical operations.A table is programmatically equivalent to an array of tuples.

*The route structure of a rest api resembles a file path in a nested file tree.
*json objects resembles how a folder looks like in the sidebar of a code editor.
*In other words,the folder structure handles data in terms of oop
*A scaffolding utility is like a constructor that creates a new folder based on a pre created one acting as a class

*The prisma client is not an api but it mirrors some of the rest api principles.For example,the synatx to perform a resource on a model:prisma.model.operation resembles host/resource/route for a rest api.It exposes many methods for performing operations on data models.you can also think of the prisma client like the whole database in object terms.The syntax prisma.user.create means access the prisma database,then the user model and then call the create method

*The prisma client creates a type safe experience and acts like an api but is best described as an orm

*The difference between prisma and plain orms is that prisma allows us to define our models are defined in a language specfically for that over classes.Prisma migrate maps the models to sql queries

*The pandas library is for working with data in python as tables
*Csv can represent table data and json can represent object data
*js emphasizes on functional and async programming.The functional paradugm focuses on creating reusable pieces of logic

*Orms bridges the gap between the two mental models of data--as objects and as tables

*The OOP paradigm is a way programmers like thinking of their data but database engineers think of their data in tables.In oop,we make queries on our data using the seamless dot notation but for tables,we use queries.So thats why python is great for data science.They emphasize a lot on oop

*Normalization refers to splitting a huge data set into multiple tables

*data models are like interfaces but for your data.They define the structure and shape of your data.Data models are defined at two layers:the database and the app.At the db layer for sql,the model is represented as tables and for mongo db,as a collection.That's why mongoose schema is for a collection.Table of records is to a Collection of objects.A collection is programmatically equivalent to an array of objects.At the app layer,data is modelled or structured either by using classes,interfaces or structs.The mental model of data s objects is why document oriented dbs are more intuitive for devs that thinks of their data as objects over tables like in sql.

*Mongoose allows us to define a model for our database

*There are three ways of writing sql in your backend:raw,query builder and orms

*For tables,data is flat and cant be nested,so a foreign key and join is used to resemble thisbut for objects,data can be nested with dot notation.

*Plain Orms allows developers to think of their data as objects.Orms under the hood,uses lots of joins to map nested object structure to sql which can lead to performance issues

*Sql builders:It allows us to write sql queries by constructing them with a builder pattern which means that we chain methods that resembles an actual sql query but it makes it feel more programmatic.It is less error prone,has auto completions and prevents syntax errors.The drawback is that it still forces programmers to think of their data in sql terms and not programmatically.Programmers think of their data in objects and database engineers as tables.So thats why mongo db is more intuitive for js developers

*Raw sql query solutions like postgres.js:Full Control,low productivity.You write your sql queries in plain strings but they are cumbersome,type unsafe and providing an interface in an attemot to provide type safety is very error prone because it isnt tied directly to the schema of the database,error prone due to lack of autocompletion and is prone to sql injection.


*There is a single source of truth for all tables called the data model as defined in the .prisma file
*syntax for modifying data in prisma: prisma.model.
*all prisma queries return js objects
*I can map my models to db queires using prisma migrate
*The prisma client will expose the models for use with the backend

*Datasource tells prisma the database to connect to
*generator--for generating the prisma client
*A model is a representation of a table

*The backend communicates with the database through a driver
*nest js provies exception filters
*ts configs can affect how types are inferred

*There is a database schema and a dto.The database schema ensures that only data that adheres to the schema enters the database while dtos or zod schemas are for request safety

*To set up Typescript:
----------------------
*Manual---tsc/swc compiler,tsconfig and nodemon
*Frontend--Ts with SWC with vite
*Backend--nest js but to make it use esmodule syntax;
  *change the type in the package.json to module
  *change the module in the tsconfig to NodeNext
  *change the module resolution to nodenext
  *all imports must end with .js
  *set strict null checks and no implicit any to true.

*Prisma automatically generates types for your data based on your model.The prisma generate cmd generates those types.The generated type follows the syntax:model name + operation type

*Every change to the prisma scheme requires you to run prisma migrate to get the queries and prisma generate to regen or update the prisma client to reflect the schema.

*The $$# of my password has to be url encoded for prisma
*prisma migrate syncs your schema file with your databases

*i finally figured out why the connection string didmt work.In the connection string,hen they said replace <password> with your real password,they meant 1234 and not <1234> which is what I've been doing my entire life of using mongo and if you forgot the password,you can easily create a new user in the data base access down in the side bar and use that username and password.Having said this,i hate the installation and setup process.Another thing to notice is that for the frontend to communicate with the backend,cors has to enabled on the backend since they'll both have different origins and the server's port has to be whitelisted on the cloud database

*I also found out how to deploy my backend using docker and render.I just make a project using a docker image and use mongo db atlas for the mongo db part.I used netlify to deploy my frontend

*The graph ql,trpc,jotai,neon webs that didnt work at home worked when using gmc's wifi maybe becaue of a security stuff of the mifi or the network service

*containers communicate with each other via a network.Local host for docker containers refers to the local container and not the host machine.I have to use the service names to connect them via a network.Volumes are for persistent data and docker compose to create multi container apps.Docker hub is a registry for images not for hosting containers

*The rubiks cube--a rep of tensors

*ericperson1234$$#,Ericperson1234
*In clis,command flags are for extra options

*There is --save and --save-dev.They both install the package locally but save dev saves it as a dev dependency over a production dependency

*python introduces the practice of indentation
*npx pnpm init must come first before installing any third party packages

*Environments
--------------
*Browsers--html and css
*Game engines
*Database engines
*Containerization engines
*Interpreter
*Compilers and transpilers
*Terminal--for running clis

*Pouch db--Client side db for storing the app's data locally
*postgre sql--Server side db for user account and authentication data,log data.Genrally data that is to be managed by the admins.
*Mongo db---Server side db for synchronizing cient data with the server for backup,user sessions for quick reads and writes,shared data and user generated data.It can handle a high write volumes,so its best for storing user profiles since user profiles can vary hugely between users and change frequently


*ORMS maps sql queries to oop code as an abstraction over raw sql queries because its safer

*An index is a pointer to a record in a table for fast reads but it leads to slower writes like update and delete.There are different data types for indexes which speeds up certain queries.The default is btree

*Sequential scanning is ideal for returning a large percentage of the records,when there are no relevant records in the table.

*Use indexes for records that are frequently queried
*an array allows for random access of valuess

*Iteration is the only way to read and modify an array at the same time so the array has to be copied for safety

*Arrays are ideal for fast lookups and iterations but reading like iterating from an array and modifying it in a loop will make the indexing unpredictable so w avod it and thats why in react,we use unique ids

*You can store the return of a select query in a view which mimics but is not a table

*Truncate deletes the contents of a table and not the table structure itself unlike dropping a table which will require you to recreate the table before you can use it and truncate is faster especially o larger datasets.

*Command line flags are like passing arguments to a function but for a cli

*There are also aliases thats if i even care

*Unions is for querying for the result of two different tables but WITHOUT returning duplicate records.Union all returns duplicate records.It must be the same number of columns,the datatypes dont have to be identical but must be compatible and the order of the column datatypes must be the same

*Union and intersection keywords allows you to perform set operations on the result of each select query.Each column from each select query is treated as a set and a set operation will be done on all the records from the two sets to return a new column.

*Cross join is like a permutation function.It returns a cartesian product of two tables which means it creates a table where all the possible combinations of records from A and B are returned.The total combination is m * n where they are both the number of records

*The inner join takes all the records from db A and B and checks if they match using a join condition and if so,adds those records together in a new table else,they dont appear in the new table

*Left outer join is the same as inner join execpt that the records that dont match will be added to the resulting table but will have those unmatching columns as null

*The right outer join is a reverseof the left outer join

*Full outer join is a combination of both left and right outer join

*If all the records in one of the tables have been matched by the other,there wont be anyone left for right and left outer join to fill with null although im not exactly sure


*The select query is like return
*Joins are for combining two or more records from different tables
*Data migrations are complex in sql databases which means changing the structure of the db after its creation becomes difficult

*The insert query can either directly takes values to insert or the values from a select query

*To add a column with a not null contraint to a table that already has records,set a default value so that upon adding the column,all records will have the default value and subsequent ones will have to obey the contraint but for adding a primary key later which you should have done upon table creation,just specify the type as serial primary key and postgres will generate the keys for all records serially

*There can only be one primary key in a table because it uniquely identifies the record.Unique and primary key are the same in that they ensure that the values in a column will always be unique but only one unique key can be used as the primary key.

*You cant set the datatype of a column to null if it already has null values

*Set data type and type are the same when setting the data type of a column in a table alteration but set data type is more readable

*Component,query and reducer.The component focuses on rendering ui while the query focuses on communicating with the bakend via an api and the reducer changes global state

*Most of the business logic of the backend lives in the services since they directly communicate with the database

*Constraints are enforcements when inserting data in a database.Its like a schema from mongoose.Specifying datatypes for columns are in themselves,contsraints

*Definition,assignments,queries
*The distinct keyword is for only fetching unique data and not duplicates

*An aggregate functions is like a reducer.It stacks/cumulates values

*The where clause is for specifying or filtering out the particular data that you need based on a condition.It is equivalent to a filer.The having clause is filtering or specifying the grouped data we want to retrieve.It is for filtering based on the result of aggregate functions.The having clause must be used after grouping the data and before ordering the data.


*The with clause can temporarily store the result of a query so that you can use another query on it.It is equivalent to chaining query methods in mongo db and using mongo db aggregations

*To use group by,the syntax is:columns to be cumulated,cumulative function.When this syntax is queried,we have to provide the group by syntax because since all the values are the same,sql will have no way to group the data.If any of the column values in the queried columns doesnt have the same value as the rest,the record intersecting that column doesnt get cumulated.

*order is eeuivalent to sort
*We use the group by clause for cumulating data across many records that share the same value
*The limit statement is equivalent to projection in mongo db

*Without the as keyword,its a definition but with the as keyowrd is an alias or assignment

*Use single quotes in postgres sql
*The like clause is a boolean expression and it is for searching for data through a minimal regex pattern where % is zero,one or mor characters and _ represents a character

*Clause--Table,row,value/condition
*Connection to sql databases are outside of sql statements
*namespaces provides naming safety
*Curly braces and semicolons are features of a statically typed language

*The structure is Database--Schema--Query and Table

*The select query is for selecting a column not a row.The first part of it is the column with all the data in it.The second part is the table to select it from.The third part is the where clause which can take an expression to determine which particular row data to extract.It takes in a boolean expression

*Fields are default to null
*Database,schema/namespaces,queries
*Queries must be terminated by semicolons
*Schemas are namespaces to tables.They are used for preventing naming conflicts and managing priviledges
*Syntax of sql queries:Verb,Noun,identifier,table structure

*A flaky test is a test that produces inconsistebt results when ran multiple times and thats why we use mocks
*in cypress,fixtures are used to simulate user data to be used statically in tests
*queries commands are commands that requests elements from the DOM,action commands for interacting with the DOM and they must be chained to query commands and assertion commands are for defining expectations
*Cypress:queries,action,expectations

*You cant just write raw sql queries to prevent sql injection.Instead we use ORMS

*Most servers run on the linux OS
*Vercel and netlify are using aws under the hood

*npx is for running executable node packages

*To install cypress,create a project with vite and choose vanilla ts with the swc and then,install cypress there and run it.For the types,add cypress and node to the types array and use a glob pattern in the includes array to include all ts files

*Boids algorithm of bird flocks
*TESTS HELPS TO CATCH LOGIC ERRORS EARLY IN DEVELOPMENT AND PROVIDES REFACTORING SAFETY

*Unit tests is for testing components in isolation by asserting expected outputs against its inputs
*Property tests tests for rules and properties that a function must always hold or adhere to across a wide range of inputs.It is good for testing for edge cases that unit tests might miss
*Integration tests checks if the various app components function together as a whole
*Mutation testing helps to ensure the quality of your tests.They can catch errors caused by typos


*You can pass an option object to the arbitraries to control the properties of the values being passed

*The shrinker from fast check should be applied to all stack traces to make errors easier to read

*the aim of property based testing is to find bugs easily,not to generate random data
*fast checks makes bugs reproducible by using the same seed which will always return the same values

*A property is made up of an arbitrary which is a function that determines what types of values to generate and a predicate which is a function that takes each of the generated values as inputs to another function to test and returning a boolean value

*Runners are functions that computes a property multiple times and assert if its true.If its false,it returns the smallest number of inputs that lead to the error and not juts the first one.This is known as shrinking

*property based testing is for declaring statements that must always hold true regardless of the input


*for wallaby to detect my e2e tests,change their file config from e2e-spec to e2e.spec.ts in the regex pattern in the jest config file

*I should use before all for states that needs to be shared across my tests that wont change across tests and before each for when it changes across tests for consistent states

*Jest provides high level matchers for the things in the mock property

*Jest.spyon is used for flexibility of mock values across different tests
*jest.fn() creates a new mock while jest.mock() creates a mock from a module and jest.spyon

*mockReturnValue,mockResolvedValue,mockImplementation

*A test should have one focus which is the function or unit being tested and thus,having a mock with its own implementatio will lead to confusion about what is being tested and increase the complexities of a test.Unit testing should completely isolate the code being tested to ensure reliability and consistency.If a function's behaviour is critical to a test,its implementation should be kept straightforward.If logic is required,a mock should be created per scenario

*Calls-is an array of all the calls on that mock function.Each call is an array of the parameters passed to the function
*Results is an array of all the results from the mock function.Each result is an object specifying the type and value property where the type is whether it was a return or a thrown error and the value is the value returned by the mock

*the mock property--calls,results
*mock property holds methods about the information about the mock function.Other properties are for defining its return and also its implementation


*GET--fetch data
*POST---upload data
*PUT--update a resource entirely
*PATCH---partially updata a resource
*DELETE--delete a resource

*for get and delete,we use url segments,path parameters,and query parameters for their requests
*while post,put and patch use a request body for payload


*the difference between regex and a glob pattern is that regex for powerful string matching and glob patterns are for file paths

*Nginx has master and worker processes.The master process manages worker processe whil worker processes serves a request.Nginx consists of modules which are controlled by directives specified in the configuration file.There are simple and block directives

*The docker run command runs a container from an image
*There is docker hub which is like github but for docker containers

*Distributing the frontend and shipping the backend
^Dont forget about mcmodels website for minecraft
^Lagging background processes of an app can prevent the desktop app from opening

^anime power:you can only touch a shell or decoy of the person.His power hides him from any physical intercations and can only be interacted through a function that returns a decoy of him.Him and the decoy exist in the same space coordinates but only one can be seen at a time.Any attempt to attack him only attacks the decoy or shell and it shatters off when the character garbage collects it revealing the true character.Visually,it will look like how a character dies and respawns in a video game


^table tennis,pen spinning,air hockey

*In docker,we install dependencies first before src code so that we dont install our modules on every src code change.It allows for caching

*react favours functional programming

*Function constructor evaluation is safer than pure eval because the string is only evaluated as a return from a function but Math js provides safer and more complicated evaluations for math expressions.

*Feature based architecture aims to solve the problems from tight coupling of components

*Tauri uses native web views.Native webviews are software components that allows an app to display web content without a browser.It is like a tiny browser
*NW js packages a node js server and chromium together in a single runtime allowing you to leverage node modules and broswer apis in one place
*Electron packages chromium to execute your app.


*In javascript,using lamba functions is highly common because of its async and functional nature.Javascript has the largest ecosystem of frameworks,packages and libraries

*Databases,compilers and game engines are written in languages like C++ 

*There are package managers and the files you use to define package and dependency data.Js uses package.json.With python,we use toml with poetry.py manager and for js,maven

*You add the api key to the headers which is where we store metadata
*Scaffolding utility is a more professional way of saying template builder

*Pino allows you to dynamically set the log level at runtime to control the verbosity of logging or reduce log noise

*In a request,you can ship payload through query parameters for get and delete and a request body for put and post.You can also use path parameters for dynamic routing

*Axios can be ran on a node js server

*learn about ts utility types
*Path parameters starts with : while query parameters starts with ?
*tailwind allows you to know what styles applies to a tag at first glance
*Sass-css,Ts-Js,Mojo-python,C++-C

*css in js,preprocessor
*loops are procedural while recursion is functional
*Svgs are images as code and lottie files are animations as code.

*Declarative ui syntax is compiled to dom manipulation

*loop rendering in react requires a unique identifier like using the uuid package

*For dynamic rendering i.e loop and conditional,react uses template syntax,vue uses directives and sveltes uses control blocks


*Scalability of a software solution refers to its ability to handle an increasing amount of work or itscapacity to accommodate growth in various factors—such as maintainability, performance, robustness, andsafety—without requiring a complete redesign or significant changes to the architecture.

*Complexity in software refers to the increasing demand for a more ideal or sophisticated solution as the software grows. This complexity arises from the need to manage more features, integrate with other systems, and accommodate changing requirements.


*Primitives are immutable types meaning that they are explicitly copied on each modification while objects and arrays are directly mutable since they are modified using their references meaning that performing operations on primitives in functions will always be free of side effects unlike arrays and objects.To prevent side effects or direct mutation,we copy the array or the object.In js,we use the spread operator.*Spreading is an operation that allows you to selectively modify arrays and objects and keeping the rest of it unchanged.React requires that state updates should be immutable and thats why use the spread operator for objects and arrays.Arrays and objects are passed by reference because they can consume lots of memory when they are deeply nested but immutability brings safety and predicatbility.


*Eslint is the official linter for javascript
*meta frameworks brings a mini server to your frontend
*Directives in frontend components are attributes with a semantic meaning

?vscode uses monaco code editor as its text engine

*so for object destructuring, i have to use the exact names of the properties i want to unpack and if i want to rename it,i have to use colons but for array destructuring,i can unpack it with any variable name i want since it uses indexing and not properties for unpacking.For array destructuring,to selectively unpack what you need,you use empty spaces separated by commas but for objects,we use the direct property name

*endpoints are operations to a server.It can be a query for reading data or a mutation to update data on the server.Endpoint by default use get unless explicitly overriden.For every endpoint defined in a slice,rtk query will generate a hook for that

*In rtk query,it is one api slice per application.An rtk query is consisted of the base query and enpoints.The base query is a function that knows how to communicate with the server.We use the fetchbasequery which is like a superset of the fetch function.We pass in the base url there which is the main url of our server

?New anime power:A character that can reproduce favourable conditions which may be helpful
?New anime power:version control like git to revert to any state to recover from damage
?New anime power:pipes:The only use of this is to temporary create flexible pipes in his body that can act as blood vessels and control the pressure of those pipes to pulse blood without a heart
?New anime power:Characters can create paradoxes that can protect them because anybody that forces their way through a paradox will tear the universe.

*The first argument to the async thunk is the action payload.The second argument to the async thunk is an object that provides utilities like dispatch and get state and for normal thunks,they also only accept one payload

*reducers decides how the state changes in response to actions meaning that they are the only ones allowed to modify state

*The action string for async thunks is just a unique identifier for it only used by rtk for generating the action objects for the async states

*Extra reducers is for adding a function that can create reducer cases.The builder object in this function is used to add cases for creating direct mappings of action strings to arrow functions which are anonymous reducers.In an async thunk,createAsyncThunk automatically creates the pending,fulfilled and rejected properties which holds the action objects for those life cycle parts.These gets dispatched depending on the state of the promise.

*Async thunks are action creators that returns promises.They are used for dispatching actions based on the life cycle of promises.The action string used in async thunks is a unique identifier that rtk will use for the pending,fullfileed and failed life cycle states.

*A thunk can dispatch multiple actions

*null and ? like operations:null coalescing,logical or operator,optional chaining,ternary operator
?state retention,persistence,management,binding,mutation

*local state management
*Parent state management
*Context
*Atomic state management
*Redux 

*Url state management is for state persistence across page reloads

*Each of these paradigms have an sigmoid scalability-complexity curve.I think of a scalability as an imaginary function that takes into account of factors liek ease of use,capability,practical uses,etc

*local state management has a scalability curve of 100 till the complexity demands a global scope for state

*Atomic state management is where shared state is split into atoms which are independent state units that can be read and written to directly by components.They are decentralized meaning that they do not need to be provided by a parent to be used in the app

*The best part of context is that it prevents prop drilling.Contexts and redux store are provided almost the same way except that you can have many contexts but only one redux store.In redux,the store is separate from the component tree,meaning that components can subscribe to the particular state that they need from the store and they can be unaware of the state tree but for context,the components must be aware of the context data they are consuming and change in context data will lead to re-renders thus,impacting performance.For contexts,you are forced to create multiple contexts leaving some state management to the individual parents that provide it because if we use a single object as the context that holds all the global state for our app,change in one state will cause a full re-render of the others since they are in the same object that has changed leading to more performance issues

*In contexts,global data has to be splitted into many contexts and provided by separate parent components but for redux,the store can be provided to the root component.The higher the complexity of sharing context,the more the context has to be lifted up which will cause performance issues and tight coupling of components

*RTK query,RTK listeners,async thunks

context api is used with useReducers
?Teardown,lay of the lands,lego fortnite

*There are creators and the obejcet itself.A creator returns that object.So an action creator can return a plain action object or a thunk which is a function that allows us to perform side effect operations and computations.

*Middlewares can be chained

*A thunk is a term for a function that delays a computation till its needed and in the case of redux,it can delay the dispatch of an action based on computations.A thunk can allow you to accept arguments besides plain action objects like promises which will then later on dispatch real action object and create side effects

*Redux thunks are used for writing async logic.Redux Thunks are action creators that returns a function instead of a plain action object called a thunk.It is a middleware that sits in between a dispatched action and a reducer

*Reducers have the rule of being pure functions to always create predicatble behaviour
*When you dispatch an action to a store,redux uses the prefix of the action's type to determine which slice to map the action to.Thats why the key of the slice must match the name of the slice

*An action is just an object with a type and payload.They are implicitly created by redux toolkit with the name convention of their type being slice name/reducer for that action.An action craetor returns an action object and th dispatch submits that action object to the store

*reducers under the hood dont mutate state but rather use the immer library to do immutable operations

*A slice is like a route for a server.it represents a share in the store's state.Therefore,a reducer is like a controller

*so when we say counter:counterReducer in our store setup,we say that it should assign all state managment of that section to the reducer

*Each feature with its own slice and reducers
*A selector is a function that extracts a particular state from a store

*A reducer is a function that calculates the new state using the old state and an action.They must be pure meaning that they always produce the same output for the same action input given that the old state is the same.Therefore,no side effects,no random values,no async operations

*An action creator is a function that returns an action object and thus,using dispatch creates an action object using the action creator and send that action to the store

*Redux uses immutability with the immer library to ensure operation safety and preducatbility
*Redux uses the global state paradigm where state is separated from the component tree in a place called the store

*The context paradigm,the global state paradigm


*before state management,state was lifted up to parents and passed down as props to children and then use context api to prevent prop drilling

*next js adds server side logic to your react.
*Url state management also prevents the need for complex state management

*The term reducer as used in redux comes from the reduce function in functional programming.
^Learn more about functional programming

*The difference between context and store is that in context,the components that wants to use its state must be inside the context but for global state management,the store is separate from the component allowing you to access its state regardless of where your components are located

*Local state,props,prop drilling for shared state,context api,useReducer for reducers

*Context api is a low level version of global state management in react,svelete and other frontend frameworks.For svelete,the modern way is stores

*Use Service.msc to start mongo db locally and you can change the port by using mongod.cf in the bin of the mongosb folder on the disk and for the atlas,go to monog db compass then paste your connection tsring and change the password to the right one and then scroll down to advanced options and in there,you will see an authroization heading.scroll down and also change the password field there.Copy the connection string and use it in mongoose to fix that authentication error

*the name of the slice object is used to prefix the actions
*default imports can be named anything you like on import

*The actions property maps reducers to actions.The reducer property wraps all the reducers into one root reducer

*A store is an object containing the applications state which is a key-value collection of every state in the app or a slice of the app's state.You can write multiple reducers that combines into one single root reducer.The reducer is the one that directly modifies the state.The action object is like a request that tells the reducer what to do with the state.

*Action,reducer and state

*So for pure hosting,focus on both hardware and software.for Iaas,focus on everything software.for Paas,only focus on coding and forget about setup and for Baas,focus on frontend more as the provider handles common backend chores

*Iaas-infrastructure service
*Paas--app development service
*self hosting,pure hosting service,cloud hosting

*The developer is separate from the provider.The provider is responsible for managing the infrastructure while the developer is responsible for the app itself.A pure service doesnt offer things like scalability.When a provider delivers services to the povider like scalability,it becomes a cloud service

*A regular service is a fixed service that doesnt increase on demand


*web app and a cloud app.A web app like a cloud app is hosted by a provider and can only be accessed online but a web app only becomes a cloud app when it delivers services within the scope of cloud principles

?Paas,Iaas,Baas,Saas

*Session data consists of all the inpersitent data stored in the frontend throughout its use and some of it can be persisted through cookies,session apis,etc

*frontend uses two types of state:ui and variable state.in general,ui states are mainly reflected in the ui but can also influence rendering while variable states arent reflected in the ui but are used for the frontend's logic and can influence ui rendering


*backend requires a full restart per change as it is stateless but the frontend doesnt since it retains state and thus uses hmr.This is because frontend is stateful but not persistent and backend is both stateless and not persistent.So a db is the only solution for a persitent storage of state and im guessing the reason why frontend state isnt persistent is that it is only used for updating the ui and only end data is stored in the db

*Hmr in web bundlers works with the file watcher by not requiring a full page reload per change.It does this by only updating the modules that were edited leading to performance boost and reservation of state

*Nodemon and tsc compiler are file watchers.File watchers--compiler,browser refresher,rerun a script.

*so bundlers package all your frontend code and its dependencies into a single file with extra features like code optimization,real time refreshes and tree shaking.

*live server
*Context api and use reducer hooks are like low level verions of Redux

*Frontend frameworks use a compiler to convert their code into vanilla js.For react,it is babel although babel is primarily for compiling js to a backwards compatible version while others use their own compilers.The compilers convert Component written code to DOM manipulation which is its superset.Component written code is just html in javascript where js can directly manipulate that html


^Dont forget about user stories

*a template builder is a tool that scaffolds an application for developmen like svelte kit,next js
*a module,library,framework,template builder

^Tech stack quality check.It gives a score gotten from comparing how good your custom tech stack is to how good it will fulfill a project idea using user-defined metrics for the project through using data submitted from a detailed form about the project and using predefined metrics for the tech stack quality against fulfilling that project using data about each technology against the context it is being used for and how well it works with the others for fullfilling a task and secondly.Users can also emphasize which part of the form data is the most important for checking against the stack and another feature is the kanban board which will be used for the developer's skill assessment to check if he has the skills to fullfill the stack.The purpose of this app is to complement decision making

?Vite or next js installer for react

*mongo db is document oriented

*graph ql allows you to control how the response object should look like and merge multiple request sinto one meaning you can request for what you specifically ask for over allowing an http server decide the response object for you which typically sends you the whole data leaving it to the fronyend to filter out the data it needs.With a normal http server,you have to create separate api endpoints for every precise data you wnt like how i have load all boards and load a board as separate requests which is inefficient.with graphql you can freakin batch requests unlike rest.graph ql ships errors in the response object and not through status codes and as such,errors can be treated as value.Rest apis deliver static responses but graphql allows us to make that dynamic but the dynamism of  graphq can lead to inconsistent responses per request body unlike rest apis that are indempotent which guves the same response for the same request regarless of how many times it is requested.  

*in rest apis/http servers,urls are used to define resources on the cloud
I want to research on the app i want to make,use ai software designer,watch yt videos on how to work about the app

vercel them are infrastructure as a service
electron,deployment and hosting,docker

Docker and kubernetes,graphql,Terraform with Azure,hostinger

Azure for various cloud services

docker is for containerizing backend services and its dependencies in an isolated environment allowing you to use it on another machine without ever worrying about reinstalling dependencies,environment setup and whether it works on your machine and not on others.it will make it work on any machine the same way as yours regardless of os.


*sessions are just a way to manage temprorary state in a server
*Because servers dont retain states,the request has to contain the full data to ensure requests are independent
*servers are completely statless and they need a database to retain state while components are stateful but lose their state once they are destroyed unless stored in a database

?LAN setup.listen on all ports,allow node js through firewall,use local ip on external machine

*use flex shrink-0 to ensure images dont shrink
*In a boolean array holding selected values,only one can be selected at a time but more than one can be deselected at a time

Client bounding rect returns the element's surface area and relative position to the viewport
*The dimensionality of data increases as the app becomes more complex
?pick tool,time,burn down charts,custom columns

*react uses functional component structure while svelte uses sfcs
*Ill only use python for app intelligence using data science and machine learning

*In js,logical operators unlike python returns the original values rather than the boolean values.They only get implicitly converted to boolean values in condition checks.The and operator returns the first falsy value it finds and for or,the first truthy value it finds and they both return the last values if all operands are truthy or falsy which allows for short circuiting condition checks.And there are logical assignment operator which does both assignment and logical evaluation in a shorter expression

*ill use stores and a one push and pull architecture

Normal people when they see it: 🥱
Developers when they see it: 🧐🤔🫡😮‍💨🗿


*svelte binding and stores
The most independent parts of the program must be coded first before the dependent ones
The server should be operationally feature based while the frontend shouldbe visually feature based
Use a boolean array to check for selected values and apply styles based on them
ai--utility snippet maker
I have to use indexed db as a fallback to the server.immediately there is connection,the data is synced with the server
!Not so scalable architecture:Refresh cycle and lever system
so my architecture is this:for A:pull initial data(data that was saved from using the app previously),push new data and dynamically tag data based on interactions while for component B:load intitial data,pull the tagged data and using an effect hook to always pull data whenever A pushes.The parent uses a store.i call the store a lever because it only flicks between true or false.So when A pushes data,it flicks it on or set the store's value to true,then the parent will then pass a state that is subscribed to the lever as a prop to B which uses the effect hook to always listen for when the prop changes to always pull data whenever A pushes.The only prop a component will listen to is the one that will notify it whenver A has pushed to the server and also,after A pushes and sets the lever to true,it then immediately on the next line toggle it to false so that the next push will toggle it again for B to listen to.I am also going to use stores for more than just levers.Anything shareable at this point should use one.The point of levers is to sync components an other stores like numbers or strings for sharing values wuth other components in real time.

component based architecture uses reactive and event driven programming

class: directive in svelte
You can only read the response body text
Operation safety can increase performance by preventing unecessary computations
Request safety and operation safety

Not adhering to the interface when sending request data can lead to errors
*Types of storage:cookies,sessions,local storage,database
GET and DELETE: Use query strings and path parameters.
POST and PUT: Use the request body to send data.
Operation safety
nest js is based on angular and is opionated while express is unopinionated

so there is a difference between using the downloaded and the deployed version of an app.In the deployed version,the client doesnt download anything,the frontend is deployed on something like vercel and the backend is hosted on a hosting playform like hostinger and the data can be stored on a cloud service while in the downloaded version,it can be fully contained but the backend must use a local storage db like sql lite or indexed db i.e both the front and backend or a mix where the frontend is downloaded but the backend is hosted on a hosting platform

Mongodb atlas,Aws,google cloud services,Azure

?API versioning
?Communicating api version between client and server
?Version control middleware
?Service worker for update checks

Object vs relational database 
Document vs Table database

Deploy the frontend
Host the backend
Cloud service to store backend's data

You can use logical operators,guard clauses and early returns to shorten if statements

render for hosting backend and vercel for frontend
canvas tag for drawing graphics in an html page using js

graphiql
get exactly what you want
Dgraph database
?we use npm install to install project dependencies as dictated by the package.json
myG1thu61234$$#

shiny object syndrome
Python--forensics,data science,machine learning,cyber security,networking

Auto save
watch compiler
live runner

HTML notebook--a notebook but you write the notes with html which allows yoy to make a webpage as a notebook
zod schema validation library.Schema defines the structure and constraint of data for validation and integrity--validation logic
DTO is for shaping the data structure sent over a request/response 
type interfaces doesnt enforce runtime validation--purely type checking

the unknown type is safer than the any type because you have to narrow it down to a type before using the value unlike the any.We use it fo rvalue sthat we dont know at compile time
nest js decorators
null safety
havent learnt regex yet
HTTP protocol and mvc architecture,component based architecture
the process module for controlling the lifdecycle of a program
package.json
*FOLDER STRUCTURE OF FRONTEND
*FOLDER STRUCTURE OF BACKEND


copy my tsconfig.json from the mongoose-ref folder across all ts projects

Router--mounts/maps controllers to a route
view
controller--routehandlers and middleware
model

http server vs tcp server
obsidian,codieum,beehive,heatmap ai,readme.so
perplexity ai

*local  and pinno for js
json.stringify tells js to covert an object to its json string and not the string as dictated by the string dunder method
Dynamic import only imports code when the user needs it
coolors
Check on pinno

Environments
-------------
Browser
Interpreted environments
System environment
Db engine
game engine

*After this web dev,ill go back tp python---C# and Java---low level ones

!There is PyPy,Cython and now Mojo
cursor code editor
coolors.co web


Mongo db environments
----------------------
Mongo db Atlas--cloud service for mongo db
Mongo db entreprise edition
Mongo db community edition


UI--atlas ui,compass ui
Shell---mongosh,Mongo db vs code playground
script--Mongo db shell contained in a js file
Mongo db drivers---mongodb npm package,mongoose


invincible 
murder drones


typo error
Hard drive,laptop
jsdom
markdown for docs like readme files
.env files are for declaring environment variables 
glob pattern
cookies are already in express js
In my online shop,if you want to add an item visually and not through the json file,i can connect my frontend with my backend using a post request.The server will then parse it into the json file


for ts in code runner:tsc & node
: typeof import('http')
etc,api protocols,authentication,api security.HTTP request are done through apis like fetch api for js and request for python
Svelte is much more declarative than react
in svelte,we use stores for shared state,check on jotai for react
state,props,two way data binding,context,stores,modules

null coalescing operator prevents errors that come from null objects in advance
Typescript scales Javascript because you can craft a type system
Typescript just makes js type safe and thherefore preventing errors before running the code

sync code,microtasks,macrotask,callbacks,promises--executor and consumers,os operations,async functions,await keyword
online delivery analogy for api
Remake my file sender using web sockets and async code
awaited ops are microtasks
The promise itself has its own function
abstraction
A promise maintains state.it takes an executor function that modifies a state

Async functions always return a promise and are non blocking and allow the use of the wait keyword
synchronous code,micro tasks,macro tasks

are functions with the async keyword a micro task

HTTP requests,Rest,CRUD,100,200,300,an inempotent operation is like a pure function but for crud ops,stateless ops.
Pagination,GraphQL
Web sockets are the web implementation of the sockets i used in python.It means that once i learn web sockets,i can create a full blown file sender app with gui and everything anot to mention promises.
sockets and apis are easier implementations of establishing communication between different softwares
GraphQL is like SQL but for APIS

Hard coded vs dynamic
Algol--C--the rest liek python
Install ts compiler through npm and use this cmd in pkg.json:
{
    "scripts": {
        "watch":"tsc --watch",
        "ts": "node script.js"
    }
}
use the at method to access negative indexes in arrays in js
install concurrently to run multiple cmd at the same time
Dvh
Svelte has two way data binding using the bind dirtective--GG

Svelte's routing is the best of both worlds:seamless SPA experience but ssr
Quick snippets--like tailwind but utility snippets that is just as customizable
node js is like nest js for node
express js

page server is the same as page client buit for operations that shouldnt be exposed to the client. ie only on the server
The page server loads first and returns whatever data it has to the client.
OMO!!Use all my codes as ref

position relative doesnt remove the space the element takes in it container
context,script modules,page and layout data
use this: data-sveltekit-noscroll to maintain scroll position when routing

+page.svelte--for data in a page and +layout.svelte for common stuffs between webpages
Array.from method for the each block in svelte

Can write a storybook--use .js extension
no error highlighting--dont install eslint
made fonts possible---used preview-head.html and paste the font links and select the font name class
props--i forgot to interpolate props in back ticks
staticDirs: ['../static'] and a restart.to make images work
import '../src/app.css'; for tailwind classes to work
Default.parameters = {
  layout: 'centered', // Center this specific story
}; for centering your stories


for using tailwind styles in storybook,i have to import the global css styles into it and for font in svelte,paste the link in page.html and extend tailwinds them to include the fonts
custom css and js extension for vs code
dribble.com for web designs

We use maps for loop rendering in react
Anything that has the length property in js is treated as an array
The same way images in react can only be placed in the public folder,for svelte it is in the static folder
gitignore file.
knowing how to get to somewhere from somewhere
I have to learn cyber security
study pattern--using notes---Ill move to obsidian notes very soon---OBSIDIAN,JUPYTER NOTEBOOK
Reading for Jamb


So svelte files use SFCs
script type=module
jsx is syntatic sugar for js function calls

retrace

I can use post css to get styled components to use the @apply rule creating tailwind vue styled components
I can create a styled component that inherits from multiple onres through string interpolation
Separation of concerns.All my styled components go in one dir,text content in another dir while the markup and script in one component place.Ill use json for the text content
ill use front end js lib for my games ui
A bot that can beat reCaptcha

<!--
For mobie,it is all about prioritizing content over ui
min width and max width
Imperative vs Declarative

Tailsasscss--For responsive designs
I use react for form validation over normal js
Tailwind uses atomic classes
Semantic html
Ill export my styled components all into a buffer so that i can reuse components i have made before.It will be my own bootstrap.
Tailwind dark theme
git revert

flex grow,shrink and wrap to be used with responsive design
extend and override themes for responsive design
query strings formy multi step form
hamburger menu
free pik
I love 4k astronaut wallpapers
-->


tailwind container tag
meta frameworks
session,cookies storage
A very interactive jupyter notebook doc of web dev



spa--client side rendering
interactive ui--two way flow of information
CDN,web sever
view layer,back end layer


STATIC RENDERED WEB APPS 
--------------------------
Pre generated
No server requests
Can not change dynamically.Changes involves a rebuild process
storage bucket--point a domain name
use huggo,jekyll


MULTI-PAGE WEB APPS
--------------------
Server side requests
Content can change dynamically
Use django,ruby on rails


SINGLE PAGE APPS
----------------
One html shell page.
js updates the page through http requests
big js bundle and higher initial load times
poor seo

SSR
----
Initial request is on the server and the page is made dynamically and js takes over to render it to the client.
MPA + SPA =SSR


SSG
----
pre render all html pages and hydrate to js after initial page loads.Redeploy whenever your site changes
Static + SPA

Hydration,Partial hydration,Island


NOTEBOOK-DAD AND PHYSICAL
Variations of the same image
there is an error when reloading the page because of a variable in order +page being initially undefined

snippet js--a syntatic sugar for function calls using comments tagged with todo

states
props
two way data binding
context
stores

dribble.com for web designs

WHAT I LEARNT IN DETAIL
Apis 
Async programming
Typescript
errors
feature based folder structure


ERRORS STUFF
Type checking
Linting

Exception handling blocks

Well Documented functions
Proper prep of the algorithm
Deep knowledge about the pl,framework and coding environment
Testing
logging
debugging

reproducing errors


OTHER STUFFS
commit message types:chore,fix,docs,feat
technical and features folder structure with directory diagram

Scaling

the build process
provide a coloring 


so abstracted from reality that you can only interact with them via a proxy
behave test for js

